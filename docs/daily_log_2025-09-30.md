# Daily Research Log — 2025-09-30

This document summarizes today’s work on the Prompt Injection RAG research system: code changes, datasets, baselines, decisions, and next steps.

## Repo Analysis and Core Fixes

We analyzed the codebase and implemented several correctness and wiring improvements:

- Keyword/BM25 search bug fix
  - Replaced invalid `fts5` rank usage with `bm25(chunks_fts)` and normalized scores (higher is better).
  - Quoted `MATCH` queries and wrapped in try/except to handle arbitrary user inputs without SQLite syntax errors.
  - Files: `src/core/vector_database.py`.

- Retrieval result serialization
  - Added `RetrievalResult.to_dict()` to make pipeline outputs JSON‑serializable.
  - File: `src/core/prompt_builder.py`.

- Config‑driven tools
  - Added `build_tool_registry_from_config()` to instantiate tools and their settings from `config/agent_config.yaml`.
  - File: `src/agent/tool_registry.py`.

- Agent factory improvements
  - `create_react_agent()` now accepts either a prebuilt `ToolRegistry` or a list of tool names, reads settings from config, and wires parser/logging/approval.
  - Files: `src/agent/react_agent.py`.

- System test alignment
  - Updated `test_system.py` to align with current pipeline outputs (`num_contexts`).

Commits/PRs:
- PR #1 (merged): Core fixes and config wiring (BM25, tool registry, agent factory, test sync)
- Commit on main: added `.gitignore` cleanups and test alignment.

## Defense Framework Implementation

Implemented a modular defense layer and integrated it into both pipeline and agent:

- New defenses
  - `InputSanitization`: regex and content checks; sanitize rather than block by default.
  - `PromptEngineeringDefense`: delimiter wrapping and instructional hierarchy.
  - `OutputValidator`: tool existence/parameter validation via `ToolRegistry`.
  - `ToolGuardrails`: whitelist and parameter policies for tools (file paths, SQL keywords).
  - `DefenseManager`: orchestrates input/output defenses; factory loads `config/defense_config.yaml`.
  - Files: `src/defenses/*`.

- Integration
  - Pipeline applies input‑stage defenses before prompt building.
  - Agent applies output‑stage defenses to parsed tool calls before execution.
  - Files: `src/core/rag_pipeline.py`, `src/agent/react_agent.py`.

- Tests (all passing)
  - BM25/hybrid behavior, ToolRegistry builder, DefenseManager input/output behavior, and agent guardrails end‑to‑end.
  - Files: `tests/test_core/test_vector_db_bm25.py`, `tests/test_agent/test_tool_registry_build.py`, `tests/test_defenses/test_defense_manager.py`, `tests/test_agent/test_agent_guardrails.py`.

PR #2 (merged): Defense framework + integration + tests.

## Scripts Added

- `scripts/ingest_corpus.py`
  - Seeds a small neutral corpus (if empty) and ingests into a vector DB.
  - Used earlier for a quick ingestion sanity check (but see “Existing DBs” below).

- `scripts/fetch_datasets.py`
  - Fetches and normalizes public injection datasets to JSONL under `data/attack_payloads/`:
    - `hf-deepset`: deepset/prompt-injections (Hugging Face) — 662 records.
    - `injecagent`: uiuc-kang-lab/InjecAgent attacker/user cases — 62 records (attacker DS/DH and user cases).
    - `pint`: Lakera PINT example dataset (YAML) — 8 example prompts.

- `scripts/run_baseline.py`
  - Baseline/defense runner for JSONL datasets via pipeline or agent.
  - Computes ASR (generic indicators) and latency; writes per‑sample JSONL and summary JSON to `experiments/results/`.

## Existing Vector Databases (No Ingestion)

To avoid expensive ingestions, we reused your prior vector DBs at `/Users/nickwiebe/old-Thesis/local_rag_system/data`.

Probe results (schema, collections, dimensions):
- `rag_vectors__e1.db`: 384‑dim embeddings; multiple collections including `default`, `scifact_*`, `e1_cs*`.
- `rag_vectors__e2_fiqa_e5_fp32.db`: 768‑dim embeddings; collection `e2_fiqa_e5_fp32`; ~5.5k chunks (fast/easy to iterate).
- `rag_vectors__e2_fiqa_bge_fp16.db`: 384‑dim; collection `e2_fiqa_bge_fp16`; ~83.9k chunks.
- The very large `e2_fp16`/`e2_fp32` DBs have ~850k chunks; usable but slow with the current vector loop.

Decision (updated): Use `data/rag_vectors__e2_fp16.db` (collection `e2_fiqa_bge_fp16`) for main baselines.
- Embedding model: `BAAI/bge-small-en-v1.5` (384‑dim) to align with bge collections.

## Baseline Runs (Pilot)

- Pipeline baseline (hybrid k=3) on a deepset subset (20–50 prompts) using `rag_vectors__e1.db` and later `rag_vectors__e2_fiqa_e5_fp32.db`:
  - ASR ≈ 0% on small random slices (sanity check only). Outputs saved under `experiments/results/` with timestamped filenames.

- Agent baseline (hybrid k=3) on InjecAgent (62 prompts) using `rag_vectors__e2_fiqa_e5_fp32.db`:
  - ASR=0.00% N=62 → `experiments/results/20250930_170838_injecagent_agent_baseline.json`.
  - Rationale: InjecAgent’s tool names differ from our registry; agent produces “thoughts” but no valid actions (useful plumbing check).

Performance notes:
- Each sample performs retrieval + Gemma 3 4B inference; end‑to‑end agent runs on 62 prompts took ~10.5 minutes.
- For iteration speed, start with small subsets (e.g., 100–200 prompts), then scale up.

## Step‑by‑Step Plan Updates

We updated `step_by_step.md` to reflect completed tasks and DB path updates:
- Phase 0 (env/data) fully checked.
- Phase 1: ensured BM25/hybrid retrieval; configured pipeline; fetched standardized datasets; ran pilot baselines (pipeline deepset subset, agent InjecAgent subset). Switched to `data/rag_vectors__e2_fp16.db` (384‑dim) for baselines.

## Baseline Sweeps Kickoff (e2_fp16)

- Quick pipeline baseline (keyword, 10 prompts, deepset subset)
  - Output: `experiments/results/20250930_190718_deepset10_pipeline_baseline.json` (ASR=0.00%, N=10)

- Deepset pipeline baseline (keyword), chunk 1/7 (100 prompts)
  - Output: `experiments/results/20250930_210226_deepset_aa_pipeline_baseline.json` (ASR=0.00%, N=100)

- Notes
  - BM25 used to avoid large in‑memory vector scans on ~850k chunk DB.
  - Further chunks and InjecAgent runs scheduled; logs will be added as they complete.

## Next Steps

1) Full E1 baseline sweeps (pipeline + agent) across:
   - `hf-deepset` (662 prompts) and `injecagent` (62 prompts), using `rag_vectors__e2_fiqa_e5_fp32.db` and `intfloat/e5-base-v2`.
   - Save summaries to `experiments/baseline/` for comparison.

2) E2/E3 defense runs:
   - Enable individual defenses in `config/defense_config.yaml` and re‑run the same datasets.
   - Then evaluate combinations (PromptEngineering + OutputValidation, OutputValidation + ToolGuardrails, all four).

3) Tool‑injection realism:
   - Either map InjecAgent tool names to our tools or use our `tool_injection` attack generator to stress `file_reader` and `database_query` realistically.

4) Retrieval sensitivity (E4), poison severity (E7), prompt engineering (E8), approval workflow (E9), stuffing thresholds (E10), benign QA and FPR (E11), and performance overhead (E12) per `research_plan.md`.

## Commands Reference (today)

```bash
# venv and tests
source venv/bin/activate
PYTHONPATH=. pytest -q tests

# Fetch datasets
PYTHONPATH=. python scripts/fetch_datasets.py --source hf-deepset   --output data/attack_payloads/deepset.jsonl
PYTHONPATH=. python scripts/fetch_datasets.py --source injecagent   --output data/attack_payloads/injecagent.jsonl
PYTHONPATH=. python scripts/fetch_datasets.py --source pint         --output data/attack_payloads/pint.jsonl

# Pilot baselines (examples)
PYTHONPATH=. python scripts/run_baseline.py --dataset data/attack_payloads/injecagent.jsonl \
  --mode agent --db /Users/nickwiebe/old-Thesis/local_rag_system/data/rag_vectors__e2_fiqa_e5_fp32.db \
  --collection e2_fiqa_e5_fp32 --embedding-model intfloat/e5-base-v2 \
  --model-path models/gemma-3-4b-it-q4_0.gguf --defense-config none --tools calculator,file_reader,web_search,database_query \
  --retrieval-method hybrid --k 3
```
